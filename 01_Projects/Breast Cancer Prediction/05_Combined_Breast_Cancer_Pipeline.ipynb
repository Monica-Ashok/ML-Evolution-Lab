{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21fab0c5",
   "metadata": {},
   "source": [
    "# Breast Cancer Prediction: A Complete Machine Learning Workflow\n",
    "\n",
    "This notebook presents a complete, beginner-friendly machine learning pipeline using the Wisconsin Breast Cancer dataset. \n",
    "\n",
    "Chosen as my first ML project, it offers a real-world, impactful problemâ€”predicting whether a tumor is malignant or benignâ€”while remaining approachable for newcomers. The dataset is well-structured, widely studied, and allows for hands-on practice with essential ML steps: data preprocessing, exploratory data analysis, model experimentation, and evaluation. \n",
    "\n",
    "By working through this project, you'll gain practical experience with the end-to-end workflow of building, interpreting, and validating a predictive model in a healthcare context.\n",
    "\n",
    "This database is also available through the UW CS ftp server:\n",
    "ftp ftp.cs.wisc.edu\n",
    "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
    "\n",
    "Also can be found on UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f3e46b",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. [Data Preprocessing](#Data-Preprocessing)\n",
    "2. [Exploratory Data Analysis](#Exploratory-Data-Analysis)\n",
    "3. [Model Experimentation](#Model-Experimentation)\n",
    "   - [3.1 Feature Engineering for Modeling](#31-Feature-Engineering-for-Modeling)\n",
    "   - [3.2 Train/Test Split (Stratified)](#32-TrainTest-Split-Stratified)\n",
    "   - [3.3 Model Training & Evaluation (Before Hyperparameter Tuning)](#33-Model-Training--Evaluation-Before-Hyperparameter-Tuning)\n",
    "   - [3.4 Model Comparison Table (Before Tuning)](#34-Model-Comparison-Table-Before-Tuning)\n",
    "   - [3.5 Hyperparameter Tuning](#35-Hyperparameter-Tuning)\n",
    "   - [3.6 Model Comparison Table (After Tuning)](#36-Model-Comparison-Table-After-Tuning)\n",
    "4. [Final Model and Evaluation](#Final-Model-and-Evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8af2933",
   "metadata": {},
   "source": [
    "## 1. Data Preprocessing\n",
    "<a id=\"Data-Preprocessing\"></a>\n",
    "Steps: Data loading, cleaning, feature engineering, and preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632bd725",
   "metadata": {},
   "source": [
    "### Expert Explanation: Data Preprocessing\n",
    "\n",
    "Data preprocessing is the foundation of any robust machine learning pipeline. In real-world scenarios, raw data is often noisy, incomplete, or inconsistent. Here, we load a pre-cleaned version of the Wisconsin Breast Cancer dataset to ensure that our analysis is not biased by data quality issues. This step includes:\n",
    "- **Data loading:** Brings the dataset into memory for analysis.\n",
    "- **Cleaning:** Ensures missing values, duplicates, or irrelevant features are handled (already done in this dataset).\n",
    "- **Feature engineering:** Prepares features for modeling, which can include scaling, encoding, or creating new features (if needed).\n",
    "\n",
    "> **Conclusion:** Proper preprocessing ensures that subsequent analysis and modeling are reliable and that results reflect true patterns in the data, not artifacts of poor data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5dd3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from scipy.stats import skew, kurtosis, zscore\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load the cleaned dataset\n",
    "df = pd.read_csv('Data/Wisconsin Breast Cancer Dataset_cleaned.csv')\n",
    "print(df.head(5))\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6d3e26",
   "metadata": {},
   "source": [
    "## 2. Exploratory Data Analysis\n",
    "<a id=\"Exploratory-Data-Analysis\"></a>\n",
    "Visualizations and statistics to understand the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc9892",
   "metadata": {},
   "source": [
    "### Expert Explanation: Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA is a critical step to understand the structure, distribution, and relationships within the data before modeling. Here, we:\n",
    "- **Visualize class distribution:** To check for class imbalance, which can bias model training and evaluation.\n",
    "- **Compute summary statistics, skewness, and kurtosis:** To identify non-normality, outliers, and feature distributions, guiding further preprocessing or model selection.\n",
    "- **Visualize features and correlations:** To spot informative features and multicollinearity, and to hypothesize which features may be most predictive.\n",
    "\n",
    "> **Conclusion:** EDA provides intuition about the data, reveals potential pitfalls, and informs the choice of models and preprocessing steps. It is essential for building trust in the data and the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb600f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target class distribution\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='target', data=df, palette='coolwarm')\n",
    "plt.title(\"Diagnosis Class Distribution\")\n",
    "plt.xticks([0,1], [\"Malignant\",\"Benign\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d42de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart\n",
    "plt.figure(figsize=(5,5))\n",
    "df['target'].value_counts().plot.pie(autopct='%1.1f%%', labels=[\"Benign\",\"Malignant\"])\n",
    "plt.title(\"Target Class Proportion\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad011d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(df.describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56ca414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skewness\n",
    "skewness = df.drop('target', axis=1).apply(skew).sort_values(ascending=False)\n",
    "print(\"\\nðŸ“Œ Skewness:\\n\", skewness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a2c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kurtosis\n",
    "kurt = df.drop('target', axis=1).apply(kurtosis).sort_values(ascending=False)\n",
    "print(\"\\nðŸ“Œ Kurtosis:\\n\", kurt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc44ce4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms of all features\n",
    "df.drop('target', axis=1).hist(figsize=(15,15), bins=30)\n",
    "plt.suptitle(\"Histograms of Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf13415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KDE plot: mean radius by class\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.kdeplot(df.loc[df['target']==0,'mean_radius'], label=\"Malignant\", shade=True, color=\"red\")\n",
    "sns.kdeplot(df.loc[df['target']==1,'mean_radius'], label=\"Benign\", shade=True, color=\"green\")\n",
    "plt.title(\"Distribution of Mean Radius by Class\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a226578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(df.drop('target', axis=1).corr(), cmap=\"coolwarm\", center=0)\n",
    "plt.title(\"Feature Correlation Heatmap\")\n",
    "plt.show()\n",
    "# Features most correlated with target\n",
    "target_corr = df.corr()['target'].drop('target').sort_values(ascending=False)\n",
    "print(\"\\nCorrelation with target:\\n\", target_corr.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee9b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outliers per feature using Z-score\n",
    "z_scores = np.abs(zscore(df.drop('target', axis=1)))\n",
    "outliers = (z_scores > 3).sum()\n",
    "print(\"\\nOutliers per feature:\\n\", outliers)\n",
    "# Boxplot for key feature\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='target', y='mean_radius', data=df, palette=\"coolwarm\")\n",
    "plt.title(\"Outlier Check: Mean Radius by Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a625533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot\n",
    "sns.pairplot(df[['mean_radius','mean_texture','mean_smoothness','target']], hue='target', palette=\"coolwarm\")\n",
    "plt.show()\n",
    "# Violin plot\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.violinplot(x='target', y='mean_area', data=df, palette=\"muted\")\n",
    "plt.title(\"Violinplot of Mean Area by Class\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647b09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA projection\n",
    "pca = PCA(n_components=2)\n",
    "pca_result = pca.fit_transform(df.drop('target', axis=1))\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=pca_result[:,0], y=pca_result[:,1], hue=df['target'], palette=\"coolwarm\")\n",
    "plt.title(\"PCA Projection (2D)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629c9d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target-class-specific analysis\n",
    "group_means = df.groupby('target').mean().T\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.barplot(x=group_means.index[:10], y=group_means.iloc[:10,0], color=\"red\", alpha=0.6, label=\"Malignant\")\n",
    "sns.barplot(x=group_means.index[:10], y=group_means.iloc[:10,1], color=\"green\", alpha=0.6, label=\"Benign\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.legend()\n",
    "plt.title(\"Comparison of Mean Feature Values (Top 10)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b5534",
   "metadata": {},
   "source": [
    "## 3. Model Experimentation\n",
    "<a id=\"Model-Experimentation\"></a>\n",
    "This section covers advanced model training, evaluation, and hyperparameter tuning for all major classifiers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3b46a",
   "metadata": {},
   "source": [
    "### 3.1 Feature Engineering for Modeling\n",
    "- Fix skewness with Box-Cox transformation (for positive features).\n",
    "- Scale features with StandardScaler.\n",
    "- Select top 15 features using SelectKBest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb040e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, boxcox\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "X = df.drop('target', axis=1)\n",
    "y = df['target']\n",
    "# Fix skewness\n",
    "for col in X.columns:\n",
    "    if (X[col] > 0).all():\n",
    "        if abs(skew(X[col])) > 1:\n",
    "            X[col], _ = boxcox(X[col] + 1)\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "# Select top 15 features\n",
    "selector = SelectKBest(f_classif, k=15)\n",
    "X_selected = selector.fit_transform(X_scaled, y)\n",
    "print('Selected Features:')\n",
    "print(X.columns[selector.get_support()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7889e672",
   "metadata": {},
   "source": [
    "### 3.2 Train/Test Split (Stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890fae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83fc25d5",
   "metadata": {},
   "source": [
    "### 3.3 Model Training & Evaluation (Before Hyperparameter Tuning)\n",
    "Train and evaluate all major classifiers with default settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8cff2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix, roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(random_state=42)\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_pred_lr = log_reg.predict(X_test)\n",
    "y_prob_lr = log_reg.predict_proba(X_test)[:,1]\n",
    "print('Logistic Regression Results:')\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_lr), annot=True, fmt='d', cmap='coolwarm')\n",
    "plt.title('Confusion Matrix - Logistic Regression')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "dt.fit(X_train, y_train)\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "y_prob_dt = dt.predict_proba(X_test)[:,1]\n",
    "print('Decision Tree Results:')\n",
    "print(classification_report(y_test, y_pred_dt))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_dt), annot=True, fmt='d', cmap='viridis')\n",
    "plt.title('Confusion Matrix - Decision Tree')\n",
    "plt.show()\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "y_prob_rf = rf.predict_proba(X_test)[:,1]\n",
    "print('Random Forest Results:')\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - Random Forest')\n",
    "plt.show()\n",
    "\n",
    "# Gradient Boosting\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb.fit(X_train, y_train)\n",
    "y_pred_gb = gb.predict(X_test)\n",
    "y_prob_gb = gb.predict_proba(X_test)[:,1]\n",
    "print('Gradient Boosting Results:')\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_gb), annot=True, fmt='d', cmap='Oranges')\n",
    "plt.title('Confusion Matrix - Gradient Boosting')\n",
    "plt.show()\n",
    "\n",
    "# KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "y_prob_knn = knn.predict_proba(X_test)[:,1]\n",
    "print('KNN Results:')\n",
    "print(classification_report(y_test, y_pred_knn))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_knn), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - KNN')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb = xgb.predict(X_test)\n",
    "y_prob_xgb = xgb.predict_proba(X_test)[:,1]\n",
    "print('XGBoost Results:')\n",
    "print(classification_report(y_test, y_pred_xgb))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt='d', cmap='Reds')\n",
    "plt.title('Confusion Matrix - XGBoost')\n",
    "plt.show()\n",
    "\n",
    "# SVM\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "y_prob_svm = svm.predict_proba(X_test)[:,1]\n",
    "print('SVM Results:')\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_svm), annot=True, fmt='d', cmap='Purples')\n",
    "plt.title('Confusion Matrix - SVM')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b33ae7a",
   "metadata": {},
   "source": [
    "### 3.4 Model Comparison Table (Before Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7b31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "results_before = {\n",
    "    'Model': [\n",
    "        'Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'KNN', 'XGBoost', 'SVM'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_lr), accuracy_score(y_test, y_pred_dt), accuracy_score(y_test, y_pred_rf),\n",
    "        accuracy_score(y_test, y_pred_gb), accuracy_score(y_test, y_pred_knn), accuracy_score(y_test, y_pred_xgb), accuracy_score(y_test, y_pred_svm)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_test, y_pred_lr), precision_score(y_test, y_pred_dt), precision_score(y_test, y_pred_rf),\n",
    "        precision_score(y_test, y_pred_gb), precision_score(y_test, y_pred_knn), precision_score(y_test, y_pred_xgb), precision_score(y_test, y_pred_svm)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, y_pred_lr), recall_score(y_test, y_pred_dt), recall_score(y_test, y_pred_rf),\n",
    "        recall_score(y_test, y_pred_gb), recall_score(y_test, y_pred_knn), recall_score(y_test, y_pred_xgb), recall_score(y_test, y_pred_svm)\n",
    "    ],\n",
    "    'F1': [\n",
    "        f1_score(y_test, y_pred_lr), f1_score(y_test, y_pred_dt), f1_score(y_test, y_pred_rf),\n",
    "        f1_score(y_test, y_pred_gb), f1_score(y_test, y_pred_knn), f1_score(y_test, y_pred_xgb), f1_score(y_test, y_pred_svm)\n",
    "    ],\n",
    "    'ROC AUC': [\n",
    "        roc_auc_score(y_test, y_prob_lr), roc_auc_score(y_test, y_prob_dt), roc_auc_score(y_test, y_prob_rf),\n",
    "        roc_auc_score(y_test, y_prob_gb), roc_auc_score(y_test, y_prob_knn), roc_auc_score(y_test, y_prob_xgb), roc_auc_score(y_test, y_prob_svm)\n",
    "    ]\n",
    "}\n",
    "results_before_df = pd.DataFrame(results_before)\n",
    "results_before_df = results_before_df.sort_values(by='ROC AUC', ascending=False).reset_index(drop=True)\n",
    "print('Model Comparison Table - Before Hyperparameter Tuning:')\n",
    "print(results_before_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298b7113",
   "metadata": {},
   "source": [
    "### 3.5 Hyperparameter Tuning (GridSearchCV/RandomizedSearchCV)\n",
    "- Tune each model and show best parameters and improved metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298eaf1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "# Logistic Regression Tuning\n",
    "lr = LogisticRegression(max_iter=500)\n",
    "param_grid_lr = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear', 'saga']\n",
    "}\n",
    "grid_lr = GridSearchCV(lr, param_grid_lr, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_lr.fit(X_train, y_train)\n",
    "best_lr = grid_lr.best_estimator_\n",
    "y_pred_lr_tuned = best_lr.predict(X_test)\n",
    "y_prob_lr_tuned = best_lr.predict_proba(X_test)[:,1]\n",
    "print('=== Logistic Regression (Tuned) ===')\n",
    "print('Best Parameters:', grid_lr.best_params_)\n",
    "print(classification_report(y_test, y_pred_lr_tuned))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_lr_tuned), annot=True, fmt='d', cmap='Purples')\n",
    "plt.title('Confusion Matrix - Logistic Regression (Tuned)')\n",
    "plt.show()\n",
    "\n",
    "# Decision Tree Tuning\n",
    "dt = DecisionTreeClassifier(random_state=42)\n",
    "param_grid_dt = {\n",
    "    'max_depth': [None, 5, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10, 20],\n",
    "    'min_samples_leaf': [1, 2, 4, 6],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "grid_dt = GridSearchCV(dt, param_grid_dt, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_dt.fit(X_train, y_train)\n",
    "best_dt = grid_dt.best_estimator_\n",
    "y_pred_dt_tuned = best_dt.predict(X_test)\n",
    "y_prob_dt_tuned = best_dt.predict_proba(X_test)[:,1]\n",
    "print('=== Decision Tree (Tuned) ===')\n",
    "print('Best Parameters:', grid_dt.best_params_)\n",
    "print(classification_report(y_test, y_pred_dt_tuned))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_dt_tuned), annot=True, fmt='d', cmap='Greens')\n",
    "plt.title('Confusion Matrix - Decision Tree (Tuned)')\n",
    "plt.show()\n",
    "\n",
    "# Random Forest Tuning\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [None, 10, 20, 30, 50],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "rand_rf = RandomizedSearchCV(rf, param_distributions=param_dist_rf, n_iter=30, cv=5, scoring='roc_auc', n_jobs=-1, random_state=42)\n",
    "rand_rf.fit(X_train, y_train)\n",
    "best_rf = rand_rf.best_estimator_\n",
    "y_pred_rf_tuned = best_rf.predict(X_test)\n",
    "y_prob_rf_tuned = best_rf.predict_proba(X_test)[:,1]\n",
    "print('=== Random Forest (Tuned) ===')\n",
    "print('Best Parameters:', rand_rf.best_params_)\n",
    "print(classification_report(y_test, y_pred_rf_tuned))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_rf_tuned), annot=True, fmt='d', cmap='Purples')\n",
    "plt.title('Confusion Matrix - Random Forest (Tuned)')\n",
    "plt.show()\n",
    "\n",
    "# Gradient Boosting Tuning\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "grid_gb = GridSearchCV(gb, param_grid=param_grid_gb, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_gb.fit(X_train, y_train)\n",
    "best_gb = grid_gb.best_estimator_\n",
    "y_pred_gb_tuned = best_gb.predict(X_test)\n",
    "y_prob_gb_tuned = best_gb.predict_proba(X_test)[:,1]\n",
    "print('=== Gradient Boosting (Tuned) ===')\n",
    "print('Best Parameters:', grid_gb.best_params_)\n",
    "print(classification_report(y_test, y_pred_gb_tuned))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_gb_tuned), annot=True, fmt='d', cmap='Greens')\n",
    "plt.title('Confusion Matrix - Gradient Boosting (Tuned)')\n",
    "plt.show()\n",
    "\n",
    "# KNN Tuning\n",
    "param_grid_knn = {\n",
    "    'n_neighbors': [3, 5, 7, 9, 11, 15],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "knn = KNeighborsClassifier()\n",
    "grid_knn = GridSearchCV(knn, param_grid_knn, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_knn.fit(X_train, y_train)\n",
    "best_knn = grid_knn.best_estimator_\n",
    "y_pred_knn_tuned = best_knn.predict(X_test)\n",
    "y_prob_knn_tuned = best_knn.predict_proba(X_test)[:,1]\n",
    "print('=== KNN (Tuned) ===')\n",
    "print('Best Parameters:', grid_knn.best_params_)\n",
    "print(classification_report(y_test, y_pred_knn_tuned))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_knn_tuned), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - KNN (Tuned)')\n",
    "plt.show()\n",
    "\n",
    "# XGBoost Tuning\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "param_dist_xgb = {\n",
    "    'n_estimators': [100, 200, 300, 500],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'subsample': [0.7, 0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.7, 0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "random_xgb = RandomizedSearchCV(xgb, param_distributions=param_dist_xgb, n_iter=30, cv=5, scoring='roc_auc', n_jobs=-1, random_state=42)\n",
    "random_xgb.fit(X_train, y_train)\n",
    "best_xgb = random_xgb.best_estimator_\n",
    "y_pred_xgb_tuned = best_xgb.predict(X_test)\n",
    "y_prob_xgb_tuned = best_xgb.predict_proba(X_test)[:,1]\n",
    "print('=== XGBoost (Tuned) ===')\n",
    "print('Best Parameters:', random_xgb.best_params_)\n",
    "print(classification_report(y_test, y_pred_xgb_tuned))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_xgb_tuned), annot=True, fmt='d', cmap='Purples')\n",
    "plt.title('Confusion Matrix - XGBoost (Tuned)')\n",
    "plt.show()\n",
    "\n",
    "# SVM Tuning\n",
    "svm = SVC(probability=True, random_state=42)\n",
    "param_grid_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': [1, 0.1, 0.01, 0.001],\n",
    "    'kernel': ['rbf', 'linear']\n",
    "}\n",
    "grid_svm = GridSearchCV(svm, param_grid=param_grid_svm, cv=5, scoring='roc_auc', n_jobs=-1)\n",
    "grid_svm.fit(X_train, y_train)\n",
    "best_svm = grid_svm.best_estimator_\n",
    "y_pred_svm_tuned = best_svm.predict(X_test)\n",
    "y_prob_svm_tuned = best_svm.predict_proba(X_test)[:,1]\n",
    "print('=== SVM (Tuned) ===')\n",
    "print('Best Parameters:', grid_svm.best_params_)\n",
    "print(classification_report(y_test, y_pred_svm_tuned))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred_svm_tuned), annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix - SVM (Tuned)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd1779b",
   "metadata": {},
   "source": [
    "### 3.6 Model Comparison Table (After Tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca45786",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_after = {\n",
    "    'Model': [\n",
    "        'Logistic Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'KNN', 'XGBoost', 'SVM'\n",
    "    ],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_lr_tuned), accuracy_score(y_test, y_pred_dt_tuned), accuracy_score(y_test, y_pred_rf_tuned),\n",
    "        accuracy_score(y_test, y_pred_gb_tuned), accuracy_score(y_test, y_pred_knn_tuned), accuracy_score(y_test, y_pred_xgb_tuned), accuracy_score(y_test, y_pred_svm_tuned)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_test, y_pred_lr_tuned), precision_score(y_test, y_pred_dt_tuned), precision_score(y_test, y_pred_rf_tuned),\n",
    "        precision_score(y_test, y_pred_gb_tuned), precision_score(y_test, y_pred_knn_tuned), precision_score(y_test, y_pred_xgb_tuned), precision_score(y_test, y_pred_svm_tuned)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_test, y_pred_lr_tuned), recall_score(y_test, y_pred_dt_tuned), recall_score(y_test, y_pred_rf_tuned),\n",
    "        recall_score(y_test, y_pred_gb_tuned), recall_score(y_test, y_pred_knn_tuned), recall_score(y_test, y_pred_xgb_tuned), recall_score(y_test, y_pred_svm_tuned)\n",
    "    ],\n",
    "    'F1': [\n",
    "        f1_score(y_test, y_pred_lr_tuned), f1_score(y_test, y_pred_dt_tuned), f1_score(y_test, y_pred_rf_tuned),\n",
    "        f1_score(y_test, y_pred_gb_tuned), f1_score(y_test, y_pred_knn_tuned), f1_score(y_test, y_pred_xgb_tuned), f1_score(y_test, y_pred_svm_tuned)\n",
    "    ],\n",
    "    'ROC AUC': [\n",
    "        roc_auc_score(y_test, y_prob_lr_tuned), roc_auc_score(y_test, y_prob_dt_tuned), roc_auc_score(y_test, y_prob_rf_tuned),\n",
    "        roc_auc_score(y_test, y_prob_gb_tuned), roc_auc_score(y_test, y_prob_knn_tuned), roc_auc_score(y_test, y_prob_xgb_tuned), roc_auc_score(y_test, y_prob_svm_tuned)\n",
    "    ]\n",
    "}\n",
    "results_after_df = pd.DataFrame(results_after)\n",
    "results_after_df = results_after_df.sort_values(by='ROC AUC', ascending=False).reset_index(drop=True)\n",
    "print('Model Comparison Table - After Hyperparameter Tuning:')\n",
    "print(results_after_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91efacd3",
   "metadata": {},
   "source": [
    "## 4. Final Model and Evaluation\n",
    "<a id=\"Final-Model-and-Evaluation\"></a>\n",
    "Select the best model, tune hyperparameters, and evaluate on test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16a7f04",
   "metadata": {},
   "source": [
    "### Expert Explanation: Final Model and Evaluation\n",
    "\n",
    "After identifying the best-performing model, we focus on rigorous evaluation and interpretation. Here, we:\n",
    "- **Select the top model (e.g., XGBoost):** Based on accuracy and AUC, which are appropriate for binary classification.\n",
    "- **Evaluate with confusion matrix, classification report, and ROC AUC:** This provides a comprehensive view of performance, including precision, recall, F1-score, and the trade-off between sensitivity and specificity.\n",
    "- **Draw actionable insights:** Understanding the strengths and weaknesses of the final model is crucial for real-world deployment, especially in sensitive domains like healthcare.\n",
    "\n",
    "> **Conclusion:** This step ensures our solution is not only accurate but also reliable and interpretable, supporting confident decision-making in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d5c9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final Model Training and Evaluation\n",
    "from xgboost import XGBClassifier\n",
    "final_model = XGBClassifier(eval_metric='logloss')\n",
    "final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)\n",
    "y_proba = final_model.predict_proba(X_test)[:,1]\n",
    "print('Confusion Matrix:')\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print('Classification Report:')\n",
    "print(classification_report(y_test, y_pred))\n",
    "print('ROC AUC:', roc_auc_score(y_test, y_proba))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
